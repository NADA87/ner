{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of personal-TFBertForTokenClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wRBhWmdpNJO"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VdfNkdBn0Z1",
        "outputId": "6b1a8b51-d617-4312-83e9-292d9fc44971"
      },
      "source": [
        "! pip install focal_loss \r\n",
        "import focal_loss \r\n",
        "from focal_loss import SparseCategoricalFocalLoss"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: focal_loss in /usr/local/lib/python3.7/dist-packages (0.0.6)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.4.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.10.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.32.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (1.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal_loss) (0.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (3.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal_loss) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "BB4neRpjZBRu",
        "outputId": "62bb0055-06c5-4b15-c0e3-cbb374be7ba9"
      },
      "source": [
        "! pip install transformers\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import transformers\r\n",
        "from transformers import BertTokenizer\r\n",
        "from transformers import TFBertForSequenceClassification\r\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\r\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "from itertools import repeat\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Activation #, LSTM\r\n",
        "from  tensorflow.compat.v1.keras.layers import CuDNNLSTM \r\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.initializers import TruncatedNormal\r\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy,BinaryCrossentropy\r\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy,BinaryAccuracy\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "#from tensorflow_addons.losses import SigmoidFocalCrossEntropy\r\n",
        "# And pandas for data import + sklearn because you allways need sklearn\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from transformers import TFBertForTokenClassification\r\n",
        "\r\n",
        "\r\n",
        "labels_dict = {\r\n",
        "'O'     : 0,    \r\n",
        "'B-art' :   1,  \r\n",
        "'B-eve' :   2,\r\n",
        "'B-geo' : 3,\r\n",
        "'B-gpe' : 4,\r\n",
        "'B-nat' :   5,\r\n",
        "'B-org' : 6,\r\n",
        "'B-per' : 7,\r\n",
        "'B-tim' : 8,\r\n",
        "'I-art' :   9,\r\n",
        "'I-eve' :   10,\r\n",
        "'I-geo' :  11,\r\n",
        "'I-gpe' :   12,\r\n",
        "'I-nat' :    13,\r\n",
        "'I-org' :  14,\r\n",
        "'I-per' : 15,\r\n",
        "'I-tim' :  16\r\n",
        "}\r\n",
        "\r\n",
        "data = pd .read_csv('/content/drive/MyDrive/NER/processed_ner_data_2.csv')\r\n",
        "#data1 = data.iloc[1000,:].copy()\r\n",
        "print(data.shape)\r\n",
        "ner =  pd.DataFrame({\r\n",
        "    'sentences' : data['sentences'],\r\n",
        "    'tag_str' : data['tag_str']\r\n",
        "})\r\n",
        "\r\n",
        "ner_tag_list = list(map(lambda x: x.split(',')[1:], ner['tag_str'] ))\r\n",
        "ner['ner_tag_list'] = ner_tag_list\r\n",
        "\r\n",
        "ner_tag_list_max_len =list(map(lambda x :  ['O']+x + ( ['O']*(126-len(x)))+['O'],ner['ner_tag_list']))\r\n",
        "ner['ner_tag_list_max_len_with_cls'] = ner_tag_list_max_len\r\n",
        "\r\n",
        "def tag_to_var(x):\r\n",
        "  return list(map(lambda k : labels_dict[k],x))\r\n",
        "\r\n",
        "ner_tag_list_max_len_with_cls_to_var = list(map(lambda x : tag_to_var(x), ner['ner_tag_list_max_len_with_cls'] ))\r\n",
        "ner['ner_tag_list_max_len_with_cls_to_var'] = ner_tag_list_max_len_with_cls_to_var\r\n",
        "ner.drop(index=[76,10051,19817,47591],axis=0,inplace=True)\r\n",
        "ner.head()\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "(47959, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>tag_str</th>\n",
              "      <th>ner_tag_list</th>\n",
              "      <th>ner_tag_list_max_len_with_cls</th>\n",
              "      <th>ner_tag_list_max_len_with_cls_to_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands of demonstrators have marched throu...</td>\n",
              "      <td>,O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B...</td>\n",
              "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-geo, O, O, O, O, O, B-...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Families of soldiers killed in the conflict j...</td>\n",
              "      <td>,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They marched from the Houses of Parliament to...</td>\n",
              "      <td>,O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-geo, I-...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 11, 0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Police put the number of marchers at 10,000 w...</td>\n",
              "      <td>,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The protest comes on the eve of the annual co...</td>\n",
              "      <td>,O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-geo, O,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...               ner_tag_list_max_len_with_cls_to_var\n",
              "0   Thousands of demonstrators have marched throu...  ...  [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, ...\n",
              "1   Families of soldiers killed in the conflict j...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "2   They marched from the Houses of Parliament to...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 11, 0,...\n",
              "3   Police put the number of marchers at 10,000 w...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "4   The protest comes on the eve of the annual co...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpwcYaYvdqH9",
        "outputId": "b386937c-8050-48ff-82fb-becab36cb33a"
      },
      "source": [
        "#ner = ner.iloc[0:3000,:].copy()\r\n",
        "print(ner.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47955, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8hjrB_BZMHF",
        "outputId": "7d481b03-5cfa-406c-c0b0-8d37260d9b76"
      },
      "source": [
        "from transformers import AutoConfig, TFAutoModelForTokenClassification,AutoTokenizer\r\n",
        "\r\n",
        "MODEL_NAME = 'bert-base-uncased' \r\n",
        "\r\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=18)\r\n",
        "#config.output_attentions = True\r\n",
        "#config.output_hidden_states = True\r\n",
        "#config.use_cache = True\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config)\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_token_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108891648 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  13842     \n",
            "=================================================================\n",
            "Total params: 108,905,490\n",
            "Trainable params: 108,905,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzlvXLa9ZNiE",
        "outputId": "782c0d69-476e-4f43-aba5-617b83d8e6af"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f40cdc83cd0>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7f40d0ac6a50>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f40cdb48f90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7FRlEz5ZP4-"
      },
      "source": [
        "sen_list = list(map(lambda x: x.split(),ner['sentences']))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMg7wy5WZVA9"
      },
      "source": [
        "tag_words = ner['ner_tag_list']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLZJNhYZU-G"
      },
      "source": [
        "def tag_to_var(x):\r\n",
        "  return list(map(lambda k : labels_dict[k],x))\r\n",
        "\r\n",
        "tag_var = list(map(lambda x : tag_to_var(x), tag_words ))\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYFgJBFUZU60"
      },
      "source": [
        "tokenized_inputs = tokenizer(sen_list, is_split_into_words=True,add_special_tokens=True,max_length=512,padding='max_length')\r\n",
        "#tokenized_inputs\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzSijOHiV2qF",
        "outputId": "d5239377-b2fb-4764-bcdf-428309740063"
      },
      "source": [
        "print(tokenized_inputs['input_ids'][0])\r\n",
        "print(tokenized_inputs['attention_mask'][0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 5190, 1997, 28337, 2031, 9847, 2083, 2414, 2000, 6186, 1996, 2162, 1999, 5712, 1998, 5157, 1996, 10534, 1997, 2329, 3629, 2013, 2008, 2406, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Atj4IeNYXwO",
        "outputId": "2db75f5d-4a26-480e-ec1c-57e1efde2e1a"
      },
      "source": [
        "len(tokenized_inputs['input_ids'][0])\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJQYmVq3aRTO"
      },
      "source": [
        "for i in range(0,3000):\r\n",
        "  sen_len = len(ner.iloc[i,0].split())\r\n",
        "  tag_len = len(ner.iloc[i,2])\r\n",
        "  if sen_len != tag_len:\r\n",
        "    print(i)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyA2BmY8ZU4b"
      },
      "source": [
        "def aligned_the_labels(example,tokens):\r\n",
        "  tokenized_example = tokenizer(example, truncation=True, is_split_into_words=True,add_special_tokens=True,max_length=512,padding='max_length')\r\n",
        "  word_ids = tokenized_example.word_ids()\r\n",
        "  aligned_labels = [17 if i is None else tokens[i] for i in word_ids]\r\n",
        "  return aligned_labels\r\n",
        "\r\n",
        "aligned_labels = list(map(lambda x,y :aligned_the_labels(x,y),sen_list,tag_var ))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG5GjUjNmRcm",
        "outputId": "ce1c63b5-beca-48aa-fa62-1abd15644fb1"
      },
      "source": [
        "type(aligned_labels[0][0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6VP6I2Yd1di",
        "outputId": "e50454a8-c8cf-4ff9-f869-ad6de612f24b"
      },
      "source": [
        "np.array(aligned_labels).shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47955, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UxnvgsCZUyJ",
        "outputId": "b5091082-3d57-4b98-ddb6-eaef33c4c99f"
      },
      "source": [
        "# tf.data.Dataset.from_tensor_slices(tokenized_inputs['input_ids'])\r\n",
        " # tf.data.Dataset.from_tensor_slices(aligned_the_labels)\r\n",
        "BATCH_SIZE=8\r\n",
        "EPOCHS = 1\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.00001) #lr=0.00001\r\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "loss = SparseCategoricalFocalLoss(gamma=2)\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\r\n",
        "\r\n",
        "history=model.fit(x= {'input_ids': tf.constant(tokenized_inputs['input_ids']),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids']),\r\n",
        "                      'attention_mask':tf.constant(tokenized_inputs['attention_mask'])},\r\n",
        "                  y=tf.constant(aligned_labels),\r\n",
        "                  #validation_split=0.2,\r\n",
        "                  batch_size=BATCH_SIZE,epochs=EPOCHS)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2da9906ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2da9906ec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2dc51b8c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f2dc51b8c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "5995/5995 [==============================] - 3277s 539ms/step - loss: 0.0458 - accuracy: 0.9619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAeD_um7XnMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6430167-dbcb-4219-db5b-88245b5ae4a7"
      },
      "source": [
        "pred_train = []\r\n",
        "k =1000\r\n",
        "for i in range(0,k):\r\n",
        "  a = model.predict({'input_ids': tf.constant(tokenized_inputs['input_ids'][i]),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids'][i]),'attention_mask':tf.constant(tokenized_inputs['attention_mask'][i])})[0]\r\n",
        "  a = np.transpose(a,(1,0,2))\r\n",
        "  a = a[0]\r\n",
        "  pred_train.append(list(map(lambda x : list(x).index(max(list(x))), a )))\r\n",
        "\r\n",
        "print(classification_report( np.array(aligned_labels[0:k]).ravel()   ,  np.array(pred_train).ravel()    )) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.05      0.09     19995\n",
            "           1       0.00      0.00      0.00        68\n",
            "           2       0.00      0.00      0.00        24\n",
            "           3       0.04      0.01      0.02       854\n",
            "           4       0.05      0.14      0.08       738\n",
            "           5       0.00      0.00      0.00        19\n",
            "           6       0.09      0.07      0.08       748\n",
            "           7       0.01      0.03      0.02       494\n",
            "           8       0.00      0.00      0.00       373\n",
            "           9       0.00      0.00      0.00        26\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       0.01      0.01      0.01       139\n",
            "          12       0.00      0.00      0.00        28\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.02      0.01      0.01       327\n",
            "          15       0.00      0.00      0.00       774\n",
            "          16       0.00      0.00      0.00        77\n",
            "          17       0.96      1.00      0.98    487294\n",
            "\n",
            "    accuracy                           0.95    512000\n",
            "   macro avg       0.09      0.07      0.07    512000\n",
            "weighted avg       0.93      0.95      0.94    512000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8UoFEhv1fYU",
        "outputId": "9d797b5d-da21-4a67-fc6a-6f9b4d21c303"
      },
      "source": [
        "# tf.data.Dataset.from_tensor_slices(tokenized_inputs['input_ids'])\r\n",
        " # tf.data.Dataset.from_tensor_slices(aligned_the_labels)\r\n",
        "\r\n",
        "\r\n",
        "BATCH_SIZE=8\r\n",
        "EPOCHS =10\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.00001)\r\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "loss = SparseCategoricalFocalLoss(gamma=2)\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\r\n",
        "\r\n",
        "history=model.fit(x= {'input_ids': tf.constant(tokenized_inputs['input_ids']),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids']),\r\n",
        "                      'attention_mask':tf.constant(tokenized_inputs['attention_mask'])},\r\n",
        "                  y=tf.constant(aligned_the_labels),\r\n",
        "                  #validation_split=0.2,\r\n",
        "                  batch_size=BATCH_SIZE,epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "375/375 [==============================] - 374s 979ms/step - loss: 0.0017 - accuracy: 0.9836\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 6.2962e-04 - accuracy: 0.9870\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 366s 977ms/step - loss: 4.1378e-04 - accuracy: 0.9878\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 3.1025e-04 - accuracy: 0.9880\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 2.4418e-04 - accuracy: 0.9879\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 1.9483e-04 - accuracy: 0.9867\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 1.6742e-04 - accuracy: 0.9856\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 1.4038e-04 - accuracy: 0.9850\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 1.2956e-04 - accuracy: 0.9846\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 1.1645e-04 - accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cl1YWnrZfjN",
        "outputId": "3ca62ef0-b127-401a-b9b4-37188276daad"
      },
      "source": [
        "pred_train = []\r\n",
        "k =100\r\n",
        "for i in range(0,k):\r\n",
        "  a = model.predict({'input_ids': tf.constant(tokenized_inputs['input_ids'][i]),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids'][i]),'attention_mask':tf.constant(tokenized_inputs['attention_mask'][i])})[0]\r\n",
        "  a = np.transpose(a,(1,0,2))\r\n",
        "  a = a[0]\r\n",
        "  pred_train.append(list(map(lambda x : list(x).index(max(list(x))), a )))\r\n",
        "\r\n",
        "print(classification_report( np.array(aligned_the_labels[0:k]).ravel()   ,  np.array(pred_train).ravel()    )) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00     50740\n",
            "           1       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00        95\n",
            "           4       0.00      0.00      0.00        69\n",
            "           6       0.00      0.00      0.00        97\n",
            "           7       0.00      0.00      0.00        38\n",
            "           8       0.00      0.00      0.00        29\n",
            "           9       0.00      0.00      0.00         3\n",
            "          11       0.00      0.00      0.00        26\n",
            "          12       0.00      0.00      0.00         2\n",
            "          14       0.00      0.00      0.00        51\n",
            "          15       0.00      0.00      0.00        47\n",
            "          16       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.99     51200\n",
            "   macro avg       0.08      0.08      0.08     51200\n",
            "weighted avg       0.98      0.99      0.99     51200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYtHTfzEZfdW",
        "outputId": "439e8265-7829-4ccc-8a09-41558d897ca0"
      },
      "source": [
        "# tf.data.Dataset.from_tensor_slices(tokenized_inputs['input_ids'])\r\n",
        " # tf.data.Dataset.from_tensor_slices(aligned_the_labels)\r\n",
        "\r\n",
        "\r\n",
        "BATCH_SIZE=8\r\n",
        "EPOCHS =10\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.00001)\r\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "loss = SparseCategoricalFocalLoss(gamma=2)\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\r\n",
        "\r\n",
        "history=model.fit(x= {'input_ids': tf.constant(tokenized_inputs['input_ids']),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids']),\r\n",
        "                      'attention_mask':tf.constant(tokenized_inputs['attention_mask'])},\r\n",
        "                  y=tf.constant(aligned_the_labels),\r\n",
        "                  #validation_split=0.2,\r\n",
        "                  batch_size=BATCH_SIZE,epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "375/375 [==============================] - 373s 978ms/step - loss: 1.0253e-04 - accuracy: 0.9837\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 367s 978ms/step - loss: 9.6440e-05 - accuracy: 0.9834\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 8.4352e-05 - accuracy: 0.9845\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 8.5127e-05 - accuracy: 0.9831\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 367s 978ms/step - loss: 8.7321e-05 - accuracy: 0.9834\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 366s 977ms/step - loss: 6.9501e-05 - accuracy: 0.9838\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 366s 976ms/step - loss: 6.2598e-05 - accuracy: 0.9833\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 366s 977ms/step - loss: 6.1343e-05 - accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 367s 977ms/step - loss: 6.1591e-05 - accuracy: 0.9842\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 367s 978ms/step - loss: 6.0982e-05 - accuracy: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj2GQ20HZfcP",
        "outputId": "a368e714-5baf-4084-8bf1-3144c1107f77"
      },
      "source": [
        "pred_train = []\r\n",
        "k =1000\r\n",
        "for i in range(0,k):\r\n",
        "  a = model.predict({'input_ids': tf.constant(tokenized_inputs['input_ids'][i]),'token_type_ids':tf.constant(tokenized_inputs['token_type_ids'][i]),'attention_mask':tf.constant(tokenized_inputs['attention_mask'][i])})[0]\r\n",
        "  a = np.transpose(a,(1,0,2))\r\n",
        "  a = a[0]\r\n",
        "  pred_train.append(list(map(lambda x : list(x).index(max(list(x))), a )))\r\n",
        "\r\n",
        "print(classification_report( np.array(aligned_the_labels[0:k]).ravel()   ,  np.array(pred_train).ravel()    )) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    507289\n",
            "           1       0.00      0.00      0.00        68\n",
            "           2       0.00      0.00      0.00        24\n",
            "           3       0.00      0.00      0.00       854\n",
            "           4       0.00      0.00      0.00       738\n",
            "           5       0.00      0.00      0.00        19\n",
            "           6       0.00      0.00      0.00       748\n",
            "           7       0.00      0.00      0.00       494\n",
            "           8       0.00      0.00      0.00       373\n",
            "           9       0.00      0.00      0.00        26\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       0.00      0.00      0.00       139\n",
            "          12       0.00      0.00      0.00        28\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.00      0.00      0.00       327\n",
            "          15       0.00      0.00      0.00       774\n",
            "          16       0.00      0.00      0.00        77\n",
            "\n",
            "    accuracy                           0.99    512000\n",
            "   macro avg       0.06      0.06      0.06    512000\n",
            "weighted avg       0.98      0.99      0.99    512000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dgEEln2bI_T"
      },
      "source": [
        "dump"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWhLBQCTbiCb",
        "outputId": "4abaad4e-d314-498f-c6e9-57174e587a4b"
      },
      "source": [
        "print(len(ainput_ids))\r\n",
        "print(len(ainput_mask)   )\r\n",
        "print(len(asegment_ids)  )\r\n",
        "print(len(alabel_ids)    )\r\n",
        "print(len(alabel_mask)  ) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeUkgPzb_TOg"
      },
      "source": [
        "#from transformers import AutoTokenizer, AutoModel,TFAutoModel\r\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",from_pt=True)\r\n",
        "#transformer_model = TFAutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",from_pt=True)\r\n",
        "#max_length = 128"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}